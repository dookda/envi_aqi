# Training Guide - Enhanced LSTM Model

## Current Status

âœ… **TensorFlow and all dependencies successfully installed**
â³ **Training processes currently running in background**

### Active Training Processes

1. **Quick Training** (`quick_train.py`) - Running since 12:35 PM
   - 30 days of Air4Thai data
   - 20 epochs
   - Estimated completion: 15-20 minutes total

2. **Validation Test** (`test_tensorflow.py`) - Running since 12:50 PM
   - Minimal 1-epoch test
   - Validates TensorFlow setup
   - Estimated completion: 5-10 minutes

## Training Options

### Option 1: Quick Training (Recommended for Testing)
**Purpose**: Fast validation that everything works
**Time**: 15-20 minutes
**Command**:
```bash
cd /Users/sakdahomhuan/Dev/envi_aqi/backend
python quick_train.py
```

**Specifications**:
- Data: 30 days from Air4Thai
- Epochs: 20
- Expected Accuracy: 85-92% (quick training)
- Output: Model saved to `models/enhanced_lstm_pm25.keras`

### Option 2: Full Production Training (For 95%+ Accuracy)
**Purpose**: Achieve the 95%+ accuracy target
**Time**: 30-60 minutes
**Command**:
```bash
cd /Users/sakdahomhuan/Dev/envi_aqi/backend
python train_model.py
```

**Specifications**:
- Data: 90 days from Air4Thai
- Epochs: 100
- Expected Accuracy: 95%+ (production target)
- Output: Model saved to `models/enhanced_lstm_pm25.keras`

### Option 3: Custom Training
Modify the training parameters in either script:

```python
# In train_model.py or quick_train.py

# Change data range
df = fetch_air4thai_data(
    station_id='36t',  # Change station
    param='PM25',      # Change parameter
    days_back=90       # Change days (30, 60, 90, etc.)
)

# Change training epochs
history = model.train(
    X_train, y_train,
    X_val, y_val,
    epochs=100,  # Change epochs (20, 50, 100, etc.)
    batch_size=16
)
```

## Checking Training Progress

### Method 1: Check for Model Files
```bash
ls -lh /Users/sakdahomhuan/Dev/envi_aqi/backend/models/
```

When training completes, you'll see:
- `enhanced_lstm_pm25.keras` - The trained model
- `enhanced_lstm_pm25_scaler.npy` - Feature scaler
- `enhanced_lstm_pm25_metadata.json` - Training metrics

### Method 2: Check Running Processes
```bash
ps aux | grep "train"
```

### Method 3: View Training Output
Training scripts print progress including:
- Data fetching status
- Model architecture details
- Training progress per epoch
- Final evaluation metrics
- Accuracy achievement status

## Understanding Training Output

### Successful Training Output Example:
```
================================================================================
ENHANCED LSTM MODEL TRAINING FOR AIR QUALITY DATA IMPUTATION
================================================================================

âœ“ Retrieved 2160 data points
  Missing values: 0 (0.0%)

ðŸ¤– Building Enhanced LSTM Model...
âœ“ Enhanced model built with 1,234,567 parameters

ðŸš€ Training Model...
Epoch 1/100 - loss: 0.0234 - val_loss: 0.0198
Epoch 2/100 - loss: 0.0156 - val_loss: 0.0143
...
Epoch 100/100 - loss: 0.0045 - val_loss: 0.0048

ðŸ“ˆ Evaluation Metrics:
  MAE: 3.45 Î¼g/mÂ³
  RMSE: 4.67 Î¼g/mÂ³
  RÂ² Score: 0.9234
  MAPE: 8.12%
  Accuracy (Â±5%): 96.3%

âœ… TARGET ACHIEVED: 96.3% accuracy (>=95%)

ðŸ’¾ Saving Model...
âœ“ Model saved to models/enhanced_lstm_pm25.keras
```

## Using the Trained Model

### Option 1: Via API
```bash
# Start the backend server
cd /Users/sakdahomhuan/Dev/envi_aqi/backend
uvicorn main:app --reload
```

Then use the API endpoints:
- `POST /api/enhanced-gap-filling` - Fill gaps with Enhanced LSTM
- `GET /api/model-metrics` - View model performance

### Option 2: Programmatically
```python
from enhanced_lstm_model import EnhancedLSTMModel

# Load trained model
model = EnhancedLSTMModel(model_path='models')
model.load_model('enhanced_lstm_pm25')

# Use for gap filling
result_df = model.fill_gaps(your_data, value_column='PM25')
```

## Troubleshooting

### Training Takes Too Long
- **Quick Training**: Use `quick_train.py` (20 epochs, 30 days)
- **Reduce Epochs**: Modify `epochs=20` in the training call
- **Reduce Data**: Modify `days_back=30` when fetching data

### Out of Memory
- Reduce `batch_size` from 16 to 8
- Reduce `days_back` to use less data
- Close other applications

### Import Errors
```bash
# Reinstall dependencies
pip install tensorflow scikit-learn pandas numpy matplotlib
```

### Model Not Found
- Ensure training completed successfully
- Check `models/` directory exists
- Run training script again

## Performance Optimization

### For Faster Training
1. Reduce epochs: `epochs=20` (for testing)
2. Reduce data: `days_back=30` (for testing)
3. Increase batch size: `batch_size=32` (if enough RAM)

### For Better Accuracy
1. Increase epochs: `epochs=150`
2. More data: `days_back=180`
3. Adjust learning rate in `enhanced_lstm_model.py`

## Next Steps After Training

1. âœ… **Verify Model Files Created**
   ```bash
   ls -lh models/
   ```

2. âœ… **Check Model Metrics**
   ```bash
   cat models/enhanced_lstm_pm25_metadata.json
   ```

3. âœ… **Start Backend Server**
   ```bash
   uvicorn main:app --reload
   ```

4. âœ… **Test API Endpoints**
   - GET `http://localhost:8000/api/model-metrics`
   - GET `http://localhost:8000/health`

5. âœ… **Integrate with Dashboard**
   - Use `ModelMetricsPanel` component
   - Use `AnomalyPanel` component
   - Use `ChatbotInterface` component

## Model Files Location

All trained models are saved in:
```
/Users/sakdahomhuan/Dev/envi_aqi/backend/models/
â”œâ”€â”€ enhanced_lstm_pm25.keras          # Main model file
â”œâ”€â”€ enhanced_lstm_pm25_scaler.npy     # Feature scaler
â”œâ”€â”€ enhanced_lstm_pm25_metadata.json  # Training metrics
â””â”€â”€ best_model.keras                  # Best checkpoint during training
```

## Expected Accuracy Targets

| Training Configuration | Expected Accuracy | Use Case |
|----------------------|-------------------|----------|
| 30 days + 20 epochs  | 85-92%           | Quick testing |
| 60 days + 50 epochs  | 90-94%           | Development |
| 90 days + 100 epochs | **95%+**         | **Production** |
| 180 days + 150 epochs| 96-98%           | Maximum accuracy |

---

**Note**: The system is currently training. Check back in 15-20 minutes for results.
**Last Updated**: December 14, 2025
